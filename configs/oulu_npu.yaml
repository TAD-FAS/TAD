# logger options
image_save_iter: 300        # How often do you want to save output images during training  10000
image_display_iter: 500       # How often do you want to display output images during training
display_size: 15              # How many images do you want to display each time
model_save_freq: 10            # freq (epoch) of saving models
log_iter: 100                   # How often do you want to log the training stats
test_iter: 1000
gpuID: 0
# optimization options
total_epoch: 400
batch_size: 11                 # batch size on train stage
test_bs: 32                   # batch size on test stage
weight_decay: 0.0001          # weight decay
beta1: 0.5                    # Adam parameter
beta2: 0.999                  # Adam parameter
init: gaussian                 # initialization [gaussian/kaiming/xavier/orthogonal]
lr: 0.0001                    # initial learning rate
lr_policy: step               # learning rate scheduler
step_size: 50               # how often to decay learning rate
gamma: 0.5                    # how much to decay learning rate,
gan_w: 1                      # weight of adversarial loss
recon_img_w: 1                 # weight of image reconstruction loss
recon_live_w: 5                 # weight of image reconstruction loss
recon_code_w: 0.01                  # weight of style reconstruction loss
recon_kl_cyc_w: 0.01  #0.01
m2l_depth_map_w: 0.0001
depth_map_w: 1
patch_map_w: 1
center_w: 0.01
cls_w: 1                          # classify loss
dis_updata_freq: 1           # discriminator updata frequence(Update the generator once after updating the discriminator n times)
# model options
gen:
  num_features: 64                     # number of filters in the bottommost layer
  # num_downsample: 2             # number of downsampling layers in content encoder
  num_res: 1                    # number of residual blocks in content encoder/decoder
  act: relu                 # activation function [relu/lrelu/tanh]
  padding_mode: reflect           # padding type [zero/reflect]
  mlp_dim: 256                # number of filters in MLP
  spoof_dim: 256                # length of style code
  norm_1_2: 1                       # L1 or L2 loss
  apply_shotcut: False              # whether use unet shotcut between enc and dec or not
  apply_se: True             # whether use seblock on classifier

dis:
  num_features: 64                     # number of filters in the bottommost layer
  num_scale: 3               # number of scales
  padding_mode: reflect           # padding type [zero/reflect]
  norm: none                  # normalization layer [none/bn/in/ln]
  act: lrelu                # activation function [relu/lrelu/tanh]
  n_layer: 4                  # number of layers in D
  gan_type: lsgan             # GAN loss [lsgan/nsgan]

depth:
  norm_1_2: 1 
  act: relu                 # activation function [relu/lrelu/tanh]
  padding_mode: reflect           # padding type [zero/reflect]
# data options
num_workers: 16                              # number of data loading threads 
image_size: 256                             # image size
data_root: ../autodl-tmp/portrait/oulu-npu/Protocol_1    # dataset folder location  ../autodl-tmp/portrait
# data_root: ../autodl-tmp/portrait/oulu-npu/Protocol_1     # dataset folder location  ../autodl-tmp/portrait
protocol: protocol_1